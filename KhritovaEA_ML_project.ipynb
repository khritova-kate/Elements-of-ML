{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhJ90kIgU0tv"
   },
   "source": [
    "# Multilingual Embedding-based Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа выполнена в рамках курса естественно-научного содержания (ЕНС) _**\"Элементы машинного обучения\"**_  \n",
    "Преподаватель: Шокуров Антон Вячеславович\n",
    "\n",
    "Автор: Хритова Екатерина Андреевна  \n",
    "Группа: **510**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание**\n",
    "> [Общие сведения](#section-1)   \n",
    ">> [Данные](#subsection-11)  \n",
    ">> [Мера качества](#subsection-12)  \n",
    ">> [Embeding](#subsection-13)  \n",
    "\n",
    "> [Mодель №1](#section-2)  \n",
    "> [Модель №2](#section-3)   \n",
    "> [Модель №3](#section-4)   \n",
    "\n",
    "> [Результаты](#section-5)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот блокнот основан на статьях:  \n",
    "[1] Samuel L. Smith, David H. P. Turban, Steven Hamblin & Nils Y. Hammerla, [Offline bilingual word vectors, orthogonal transformations and\n",
    "the inverted softmax](https://openreview.net/pdf?id=r1Aab85gg)   \n",
    "[2] A. Conneau*, G. Lample*, L. Denoyer, MA. Ranzato, H. Jégou, [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087.pdf)  \n",
    "[3] Armand Joulin Piotr Bojanowski Tomas Mikolov, [Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion](https://arxiv.org/pdf/1804.07745.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу машинного перевода. Пусть задано представление слов (как векторов $x \\in \\mathbb{R}^d$). Для рещения задачи будем выравнивать векторы из двух языков в едином векторном пространстве с помощью некоторого отображения $W$. Ниже представлена схема выравнимания для векторного представления английских слов $X$ и испанских слов $Y$.\n",
    "\n",
    "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)\n",
    "\n",
    "Рассмотрим следующие модели:\n",
    "1. Использующая линейное отображение между непрерывными представлениями слов.\n",
    "2. Использующая линейное ортогональное отображение между непрерывными представлениями слов.\n",
    "3. Использующая линейное ортогональное отображение между непрерывными представлениями слов, при построении которого используется корректирующая метрика.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-1\"></a> \n",
    "# Общие сведения <a name=\"subsection-11\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для исследования выберем два родственных славянских языка: **украинский** и **русский**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"subsection-13\"></a> \n",
    "## Embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для embeding-а возьмем уже готовые представления:\n",
    "* [cc.uk.300.vec.zip](https://yadi.sk/d/9CAeNsJiInoyUA)\n",
    "* [cc.ru.300.vec.zip](https://yadi.sk/d/3yG0-M4M8fypeQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на слова, наиболее близкие к слову _\"август\"_ и _\"серпень\"_ (перевод на украинский язык)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDING\n",
    "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")\n",
    "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее близкие к слову \"август\" для ru_emb:\n",
      "август     1.0\n",
      "июль       0.938\n",
      "сентябрь   0.924\n",
      "июнь       0.922\n",
      "октябрь    0.91\n",
      "ноябрь     0.893\n",
      "апрель     0.873\n",
      "декабрь    0.865\n",
      "март       0.855\n",
      "февраль    0.84\n",
      "\n",
      "Наиболее близкие к слову \"серпень\" для uk_emb:\n",
      "серпень    1.0\n",
      "липень     0.91\n",
      "вересень   0.902\n",
      "червень    0.899\n",
      "жовтень    0.881\n",
      "листопад   0.879\n",
      "квітень    0.859\n",
      "грудень    0.859\n",
      "травень    0.841\n",
      "лютий      0.826\n",
      "\n",
      "Наиболее близкие к слову \"серпень\" для ru_emb:\n",
      "Недопустимость 0.244\n",
      "конструктивность 0.233\n",
      "офор       0.233\n",
      "deteydlya  0.23\n",
      "пресечении 0.226\n",
      "одностороннего 0.226\n",
      "подход     0.223\n",
      "иболее     0.22\n",
      "2015Александр 0.219\n",
      "конструктивен 0.218\n"
     ]
    }
   ],
   "source": [
    "ruemb_to_ru = ru_emb.most_similar([ru_emb[\"август\"]])\n",
    "#ukemb_to_ro = uk_emb.most_similar([ru_emb[\"август\"]])\n",
    "ukemb_to_uk = uk_emb.most_similar([uk_emb[\"серпень\"]])\n",
    "ruemb_to_uk = ru_emb.most_similar([uk_emb[\"серпень\"]])\n",
    "\n",
    "print('Наиболее близкие к слову \"август\" для ru_emb:')\n",
    "for k in range(10):\n",
    "    print(\"{:10} {}\".format(ruemb_to_ru[k][0], round(ruemb_to_ru[k][1], 3)))\n",
    "    \n",
    "print('\\nНаиболее близкие к слову \"серпень\" для uk_emb:')\n",
    "for k in range(10):\n",
    "    print(\"{:10} {}\".format(ukemb_to_uk[k][0], round(ukemb_to_uk[k][1], 3)))\n",
    "\n",
    "print('\\nНаиболее близкие к слову \"серпень\" для ru_emb:')\n",
    "for k in range(10):\n",
    "    print(\"{:10} {}\".format(ruemb_to_uk[k][0], round(ruemb_to_uk[k][1], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNIKfTT_U0ty"
   },
   "source": [
    "В качестве исходного датасета используется файл, содержащий украинские и русские слова, разделенные табуляцией. Все буквы в словах записаны в нижнем регистре, слова не содаржат знаков препинания, цифр и пр.  \n",
    "Пример нескольких таких пар:\n",
    "\n",
    "|Ukrainian  | Russian   |\n",
    "|-----------|-----------|\n",
    "|автомобіль | автомобиль|\n",
    "|автомобіль | вагон     |\n",
    "|агов       | эй        |\n",
    "|аґрус      |крыжовник  |\n",
    "|адже       |ведь\n",
    "|...        | ...       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxuEj76QU0ut"
   },
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1600588975618,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "ifWhN0kdU0t7"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1600589414975,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "JPpwaHdPU0uu"
   },
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1192,
     "status": "ok",
     "timestamp": 1600589445195,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "TNKzMd7jU0uz"
   },
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus_train_fixed.txt\")\n",
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus_test_fixed.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"subsection-12\"></a>  \n",
    "## Мера качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве меры качества будем ипользовать долю \"близко угаданных\" слов с точностью top-1, top-5 и top-10:\n",
    "\n",
    "Для каждого преобразованного украинского представления ищется его N ближайших соседей в пространстве представления русских слов (т.е. слово переводится с украинского на русский и для полученного перевода ищется N наиболее близких по смыслу русских слов). Далее находится частота \"близко угаданных\" слов, т.е. тех, у которых хотя бы одна точка в найденной окрестности совпадает с истинным переводом.\n",
    "\n",
    "Аргументы функции:\n",
    "* Массив _pairs_ содержит пары слов из словаря (т.е. слово и его точный перевод)\n",
    "* Массив _mapped_vectors_ - это массив построенных приближений/переводов дли всех украинских слов из массива _pairs_\n",
    "* topn - точность (количество элементов в окрестности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0.\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        neighbours = ru_emb.most_similar(positive=[mapped_vectors[i]], topn=topn)\n",
    "        for neigh, _ in neighbours:\n",
    "                if neigh == ru:\n",
    "                    num_matches += 1.\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    print(precision_val)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASnu6Mr4U0t5"
   },
   "source": [
    "<a name=\"section-2\"></a>\n",
    "# Модель №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $x_i \\in \\mathbb{R}^d$ — представление слова $i$ на исходном языке, а $y_i \\in \\mathbb{R}^d$ — представление его перевода. Наша цель — узнать такое линейное преобразование $W$, которое минимизирует евклидово расстояние между $Wx_i$ и $y_i$ для некоторого подмножества представлений слов. Таким образом, мы можем сформулировать так называемую проблему Прокруста:\n",
    "\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3H8MeBMU0vA"
   },
   "source": [
    "Заметим, что $W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ выглядит как простая множественная линейная регрессия (без перехвата). Итак, давайте искать ее именно в таком виде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 754,
     "status": "ok",
     "timestamp": 1600591784764,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "e_DW25EbU0vB",
    "outputId": "cceb7ef2-f3fa-4543-a263-e65c2ae2c518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mapping = LinearRegression(fit_intercept=False)\n",
    "mapping.fit(X_train, Y_train)\n",
    "\n",
    "#Y_pred = mapping.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZ1e2TQVU0vG"
   },
   "source": [
    "Посмотрим на соседей вектора слова _\"сiчень\"_ после линейного преобразования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1600591787386,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "bSAeOnW-U0vH",
    "outputId": "0da7fa8c-3919-4c6a-9ed2-02547a0560ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее близкие к слову \"серпень\" для ru_emb:\n",
      "апрель     0.854\n",
      "июнь       0.841\n",
      "март       0.84\n",
      "сентябрь   0.836\n",
      "февраль    0.833\n",
      "октябрь    0.831\n",
      "ноябрь     0.828\n",
      "июль       0.824\n",
      "август     0.812\n",
      "декабрь    0.804\n"
     ]
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ruemb_to_uk = ru_emb.most_similar(august)\n",
    "\n",
    "print('Наиболее близкие к слову \"серпень\" для ru_emb:')\n",
    "for k in range(10):\n",
    "    print(\"{:10} {}\".format(ruemb_to_uk[k][0], round(ruemb_to_uk[k][1], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8BhDOwpU0vL"
   },
   "source": [
    "Таким образом, окрестность этого вложения состоит из разных месяцев, но правильный вариант находится на девятом месте.\n",
    "\n",
    "Т.е., если мы вычислим меру качества модели для выборки, состоящей только из слова _август_ (и его перевода), то оценка с точность top-5 даст 0.0, а оценка с точностью top-9 и выше даст 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим теперь меру качества построенной модели для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52183,
     "status": "ok",
     "timestamp": 1600591922177,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "hKp5xM_XU0vd",
    "outputId": "05752af8-1ebb-43ea-f063-589b1ac41fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6424870466321243\n",
      "0.8082901554404145\n",
      "0.8497409326424871\n"
     ]
    }
   ],
   "source": [
    "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
    "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
    "precision_top10 = precision(uk_ru_test, mapping.predict(X_test), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97Qi9Z0-U0vh"
   },
   "source": [
    "<a name=\"section-3\"></a>\n",
    "# Модель №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5yl5f5MU0vi"
   },
   "source": [
    "Можно показать (см. оригинальную статью), что самосогласованное линейное отображение между семантическими пространствами должно быть ортогональным.\n",
    "Тогда можно искать отображение $W$ как ортогональное:\n",
    "\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_2 ,\\\\ W^TW = I, \\\\I \\text{- identity matrix}$$\n",
    "\n",
    "Оптимальное ортогональное преобразование можно найти, используя разложение по сингулярным значениям. Оказывается, оптимальное преобразование $W^*$ можно выразить через компоненты SVD:\n",
    "\n",
    "$$X^TY=U\\Sigma V^T\\text{, сингулярное разложение}$$\n",
    "$$W^*=UV^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1600592050691,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "ODLDY55IU0vj"
   },
   "outputs": [],
   "source": [
    "#singular value decompostion\n",
    "\n",
    "def learn_transform(X_train, Y_train):\n",
    "    U, S, V = np.linalg.svd(np.matmul(X_train.T, Y_train))\n",
    "    return np.matmul(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1600592051808,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "HijUH5s5U0vo"
   },
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52303,
     "status": "ok",
     "timestamp": 1600592106743,
     "user": {
      "displayName": "Александра Чубчева",
      "photoUrl": "",
      "userId": "00055050786487740199"
     },
     "user_tz": -180
    },
    "id": "27vsKNc2U0vv",
    "outputId": "bdd9559f-7581-4abe-9f6c-f8dea26c7b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655440414507772\n",
      "0.8238341968911918\n",
      "0.8523316062176166\n"
     ]
    }
   ],
   "source": [
    "prescision_top1 = precision(uk_ru_test, np.matmul(X_test, W), 1)\n",
    "prescision_top5 = precision(uk_ru_test, np.matmul(X_test, W), 5)\n",
    "prescision_top10 = precision(uk_ru_test, np.matmul(X_test, W), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-4\"></a>\n",
    "# Модель №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно показать, что построенные модели страдают от так называемой \"hubness problem\": некоторые векторы слов имеют тенденцию быть ближайшими соседями аномально большого количества других слов. Одним из решений этой проблеммы является использование при выводе корректирующей метрики. В [[3]](https://arxiv.org/pdf/1804.07745.pdf) в качестве такой метрики выбирается CSLS-критерий:\n",
    "$$CSLS(x,y) = -2 cos(x,y) + \\frac{1}{k}\\sum_{y' \\in \\mathcal{N}_Y(x)} + \\frac{1}{k}\\sum_{x' \\in \\mathcal{N}_X(y)} $$\n",
    "\n",
    "Здесь $\\mathcal{N}_Y(x)$ - окрестность точки $x$ в пространстве $Y$ (k ближайших соседей) и $cos(x,y)$ - cosine similarity (косинусное сходство)\n",
    "\n",
    "Отображение $W$, как и в предыдущей модели, будем искать как ортогональное $W \\in \\mathcal{O}_d$.\n",
    "\n",
    "Задача оптимизации (_Relaxed CSLS loss_) в этом случае записывается как\n",
    "$$W^* = \\underset{W \\in \\mathcal{O}_d}{argmin}(\\frac{1}{n}\\sum_{i=1}^{n} -2x_i^TW_i^Ty_i + \\frac{1}{k}\\sum_{y_j\\in\\mathcal{N}_Y(Wx_i)}x_i^TW^Ty_j +  \\frac{1}{k}\\sum_{Wx_j\\in\\mathcal{N}_X(y_i)}x_j^TW^Ty_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCSLS(X, Y, W, k = 10):\n",
    "    n = X.shape[0]\n",
    "    X_trans = np.matmul(X, W.T)\n",
    "    # first term\n",
    "    f1 = 2*np.sum(X_trans * Y)\n",
    "    df1 = 2 * np.matmul(Y.T, X)\n",
    "    #second term\n",
    "    f2, df2 = knn_term(np.matmul(X_trans, Y.T), X, Y, k)\n",
    "    #third term\n",
    "    f3, df3 = knn_term(np.matmul(np.matmul(X, W.T), Y.T).T, Y, X, k)\n",
    "    \n",
    "    f = -f1 + f2 + f3\n",
    "    df = -df1 + df2 + df3.T\n",
    "    \n",
    "    return f/n, df/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В терминах нашей задачи:\n",
    "$$cos(Wx_i, y_j) = x_i^TW^Ty_j$$\n",
    "В то же время\n",
    "$$||Wx_i - y_j||_2^2 = 2 - 2x_i^TW^Ty_j$$\n",
    "\n",
    "Другими словами, $k$ ближайщих соседей можно искать как $k$ элементов, для которых значение $x^TW^Ty$ будет максимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_term(term_val, space_pnt, space_neigh, k):\n",
    "    neigh_pid = np.argpartition(term_val, -k, axis=1)[:, -k:]\n",
    "    shape = neigh_pid.shape\n",
    "    neigh = space_neigh[neigh_pid.flatten(), :]\n",
    "    neigh = neigh.reshape(shape[0], shape[1], space_neigh.shape[1])\n",
    "    \n",
    "    f = np.sum(term_val[np.arange(term_val.shape[0])[:, None], neigh_pid])\n",
    "    df = np.matmul(neigh.sum(1).T, space_pnt)\n",
    "    \n",
    "    return f/k, df/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим некоторые параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subsample elements\n",
    "subsetsize = 1000\n",
    "# number of iterations\n",
    "niter = 25\n",
    "# number of nearest neighbors\n",
    "k = 20\n",
    "# learning rate\n",
    "lr = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#singular value decompostion\n",
    "W = learn_transform(X_train, Y_train)\n",
    "\n",
    "X = X_train.copy()\n",
    "Y = Y_train.copy()\n",
    "\n",
    "f_old = 0\n",
    "W_old = []\n",
    "\n",
    "for it in range(0, niter + 1):\n",
    "    if lr < 1e-4:\n",
    "        break\n",
    "    ids = np.random.choice(X.shape[0], size=subsetsize, replace=False)\n",
    "    f, df = RCSLS(X[ids, :], Y[ids, :], W, k)      \n",
    "    W -= lr * df \n",
    "    f_old, W_old = f, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6606217616580311\n",
      "0.8341968911917098\n",
      "0.8549222797927462\n"
     ]
    }
   ],
   "source": [
    "prescision_top1 = precision(uk_ru_test, np.matmul(X_test, W), 1)\n",
    "prescision_top5 = precision(uk_ru_test, np.matmul(X_test, W), 5)\n",
    "prescision_top10 = precision(uk_ru_test, np.matmul(X_test, W), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "osfCMsRlU0vy"
   },
   "source": [
    "<a name = \"section-5\"></a>\n",
    "# Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценки, полученные для каждой модели, приведены в следующей таблице:\n",
    "\n",
    "|      | Модель №1 | Модель №2 | Модель №3 |\n",
    "|------|-----------|-----------|-----------|\n",
    "|top-1 | 0.6425    | 0.6554    | 0.6606    |\n",
    "|top-5 | 0.8083    | 0.8238    | 0.8342    |\n",
    "|top-10| 0.8497    | 0.8523    | 0.8549    |\n",
    "\n",
    "\n",
    "Как и ожидалось, модель №1 является худшей, а модель №3 показывает лучший результат."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
